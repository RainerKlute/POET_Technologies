# Interview transcript: POET Technologies plans to ‘semiconductorise’ photonics

- Source: <https://picmagazine.net/audio#533>

\[00:00\] **Interviewer:** Okay, so a good place to start would be with a little bit of an introduction to POET Technologies – the sort of when, why formed, any key milestones to date, that kind of information, please.

\[00:11\] **Suresh Venkatesan:** Sure. POET is a publicly traded company on NASDAQ, but it has been a publicly traded company on the Toronto Stock Exchange for a couple of decades now. It reversed into a solar company, and it had its lifecycle associated with various technologies. But really, the focus on integrated photonics is something that I brought into the company when I joined the company in 2015, and we reinvented the company at that point in time to having a focus on creating differentiation through integration, right? And that was kind of our real theme – to differentiate ourselves in this world of photonics through creating integration solutions for optics and electronics.

And so, the key milestone for the company really was around 2018 when we invented the whole concept around the optical interposer, pivoted the company towards a silicon-based integration approach versus what existed in the company before I joined, and basically relaunched the company around what we now call the POET Optical Interposer.

So we maintained the name, which originally stood for Planar Opto-Electronic Technology, because we still think that what we do is optoelectronic in nature and what we do is integrated in nature. And the fundamental vision and mission of the company associated with integration hasn’t gone away, but the implementation of the methodologies in creating these integrated solutions is what changed. And we’ve now generated a ton of IP – over 60 patents – as well as a lot of differentiation in the process technology associated with this integration.

So we’ve come a long way. Although the company itself has been in existence for a couple of decades, what we’re doing now is vastly more exciting. And particularly with the advent of AI, as we’ve been developing these concepts around the interposer, it dovetails perfectly with the needs of the AI market, where there’s this huge explosion in terms of the amount of data generated and consumed, and all of that data needing to be communicated optically, which then drove the need for integration, which then happened to fit perfectly well with our integration vision that we had for photonics. So, you know, after a few years of kind of discussing interposers and integration, suddenly there was a market demand that kind of dovetailed perfectly with what it is that we were developing. And so we’re now currently in this phase of very high interest and demand for what it is that we’re doing. And so, as a company, we’re kind of really refocusing our efforts in this area.

\[03:26\] **Interviewer:** Okay, yeah, you’ve referenced a couple of times the optical interposer. So perhaps you can just give us a bit of a flavor of what that is and the benefits it brings? It sounds as if you’re sort of continuously developing it. So, yeah, what you can share from maybe when it started out and to what it has become today?

\[03:42\] **Suresh Venkatesan:** Yeah, you know, the world’s been spending a lot of resources and time on what are called silicon photonics. And these are basically the concept of using silicon wafers and silicon waveguides to provide some form of integration in optics. And that’s been around for, I’d say, 23, 25 years, you know, and it has its advantages and it has its challenges.

Likewise, there were technologies that have been developed decades ago around what are called Planar Lightwave Circuits (PLCs), which used different waveguide materials, but they were largely passive in nature and largely only optically focused.

I think what we did at POET was marry the best of both worlds, right? So we basically took all of the advantages of silicon processing and CMOS processing and combined it with all of the benefits of what are called planar lightwave circuits and created these interposers, which are essentially an advanced passive substrate for co-integration of electronics and optics. So they have multiple layers of electrical interconnects, multiple layers of optical interconnects built into a substrate for a purpose-built application. And then we hybrid-integrate or hybrid-bond components onto it – not very dissimilar from components getting onto a printed circuit board or components getting into a multi-chip module. Likewise, here, we have components going onto our optical interposer. The key difference is that this optical interposer enables both electrical and optical components to be placed on it, whereas multi-chip modules or PCBs largely cater to the world of electronics.

So our big breakthrough, our differentiation, was to be able to create these substrates, if you will, or interposers, if you will, that are purpose-built for applications but at the same time have a cost structure and an economy of scale associated with silicon processing. And so we create kind of this benefit of silicon-based integration and growth and volumes and costs and marry with it the principles of optics assembly, which is not that easy to do because optics assembly requires a lot more things to be considered, and that’s why it’s always been somewhat boutique in nature for years. But now we’ve kind of demystified, if you will, what optics assembly needs to look like and are now able to create a platform for this integration.

\[06:39\] **Interviewer:** Okay, alongside that, I think you also do or have done some development work around photonic integrated circuits, or PICs. So, again, can you just share the sort of work that you’ve been doing on those specifically?

\[06:52\] **Suresh Venkatesan:** Sure, yeah. So the optical interposer, if you kind of go back to my previous answer, is largely a substrate. And making that substrate into an integrated circuit is the act of assembling components onto the substrate for specific applications. And then the substrate is converted into an integrated circuit, or what we call an optical engine, for specific applications. So we have photonic integrated circuits, which is an integrated set of components on the optical interposer that supports various market applications. Of course, the big ones that we’re really focused on these days are 800 gigabits per second, 1.6T, and 3.2T, and that’s largely because that’s where the largest demand is today, driven by the needs of AI, while he have solutions.

We initially started developing the technology back in 2018, and 800 gig wasn’t in existence at that point in time, and we had a lot of fundamental development to do. So we did a lot of that development around 100 gigabits per second and validated that the technology works and meets market requirements. We do have a few customers at 100 gigabits per second that are kind of vetting the technology in the manufacturing environment, and we’ve been working on that.

But the base technology we’ve developed is what we would call a platform. That means you can interchange the components onto that platform and then very quickly move up in speed. So we’ve been able to leapfrog from 100 gigabits per second to 800 gigabits per second, which we did over the past year and a half, and we’ve got a lot of customers now excited about our 800-gigabits-per-second solution because that’s a market that’s just nascent today, within very explosive growth relative to AI and then a rapid transition to 1.6T and 3.2T. We’re really focused on that. And so our photonic integrated circuits today are largely catering to customers in that space, which is 800 gig, 1.6 terabits per second, and 3.2 terabits per second. And we’re one of the few companies in the world that have actually demonstrated what are called 200-gigabit-per-lane solutions, and those solutions are necessary to extend the roadmap to 3.2 terabits. So that’s something that’s really exciting for us. I think, for the first time, as a company, we’re on the leading edge of what it is that the hyperscalers need, and we’re excited to be partnering with both customers as well as partners to demonstrate our solutions in that space through these PICs or photonic integrated circuits.

\[09:50\] **Interviewer:** Just trying that up, often, when it comes to these kinds of technologies, scaling can be the problem. But you say, you have a roadmap. You don’t have any particular challenges in getting up; you mentioned the 3.2T speeds – you can use more or less exactly the same solution and just get the speed up, or is there a cover point where it gets a bit more complicated to continue?

\[10:13\] **Suresh Venkatesan:** You know, there’s the component piece, which we rely on our partners to develop, and then there’s the interposer, which is a platform, and it does scale. It’s somewhat speed-agnostic from that perspective. I wouldn’t say that it is no work, but it is relatively less heavy lifting, if you will, to move from one speed to the other. If you’re doing a module the conventional way, every change – whether it’s 800G DR4, FR4, LR4, or ER4, or 1.6T – it’s a ground-up design. You just gonna start over because the number of components you have to integrate, whether it has a multiplexer, demultiplexer, how you align the fibers and lenses, all of that changes. So, most people that make these modules in a conventional manner, it’s a ground-up design.

For us, you buy an 800G engine, and the module design remains exactly the same. We take care of all of the optical complexity on the interposer itself. So basically, the same chip or different chips – so they buy a DR4 chip, an FR4 chip, an LR4 chip – their module remains exactly the same. All they are doing is replacing the chip on that module, and you have a completely new product. The time to market and the engineering resources that our customers need to put in to have these different form factors is dramatically reduced by using our solutions because we take care of the optical paths that they don’t now need to worry about. 

And we, of course, do it using integration and platform. So for us, it’s relatively straightforward to spin a lot of these different variants, and it’s relatively easier for our customers to use them. That’s why we’ve got engagements with Luxshare, for example, which is a Taiwanese customer, Foxconn, of course, is a household name in the space, and they are engaged with us on a multi-generational development, which is starting at 800G DR/FR, migrating to 1.6T DR/FR, and beyond. They view that as an advantage for them to use our solutions because it is inherently multi-generational and multi-form factor. They recognize that one investment in one product line of ours basically expands across a multitude of different product lines and options. We are really excited with with those design wins and of course there are others that we are keenly working on. 

The other thing we’ve noticed, especially with integration, is in the 100G, four years ago, people didn’t care too much about what we were doing because we were far ahead of the time, and what we were offering was maybe an overkill for a 100G application. But today, as we migrate to 1.6T, there are some really thorny problems like crosstalk or EMI that come into play. With our integrated solutions, some of those issues are mitigated. So more and more people are now looking towards interposer solutions as the way to go going forward. In fact, at this year’s OFC, several other companies are now starting to talk about interposers or fabrics or – I mean, things that we’ve called an interposer back in 2018. I think there’s just a resurgence of the use of that phrase, largely through a recognition of the fact that that kind of integration is going to need to be important.

So, we do expect that, from a company that was singularly in the industry doing interposers there are going to be more and more people wanting to look at solutions that are interposer-like. But we feel like we have an advantage because we’ve started early, we have an advantage because architecturally, we have done things that make it more of a platform solution as opposed to something that is very, very application specific and has to be ripped up and redone every time you change. We feel like we’re in a really good position now because the industry finally has caught on to the fact that the solution we’ve been developing over the past four or five years is in fact the approach that most people are taking: 3D integration in photonics, 3D assembly techniques in photonics, using interposers. I’m happy that the industry is catching on. It provides us with a lot of opportunity but of course a lot of competition as well.

\[14:54\] **Interviewer:** Yeah, I know you also talk about wanting to bring … or the company’s mission is to semiconductorize the photonics. So is that what you’ve been sort of discussing – the way you can build the platform so it’s much easier for people to then use? Or are there other things that you’re doing or planning to do to semiconductorize the photonic space?

\[15:16\] **Suresh Venkatesan:** Yeah, I think the phrase semiconductorization of photonics really is kind of looking at how photonics was being used in the past 20, 30 years. Most of the assembly has been boutique, and built to not necessarily scale, and with significant scale not really in mind. 

Now, as you look at these AI technologies and requirements, there is a big thrust for more data, which means more optics. The volumes are very, very high in the world of semiconductors. So, we feel that for optics to keep up in speed with those kinds of volumes, demand, and growth, that optics needs to look like semiconductors. It needs to be built using the same fabs, it needs to be built using the same equipment, it needs to largely leverage on the billions and billions of dollars of investment that have gone into the semiconductor space to effectively catch up in terms of scale, volume, cost, and performance.

And so, the term “semiconductorization of photonics” is really trying to take photonics assembly – not necessarily the components, because those components are very material-focused, whether it be indium phosphide, silicon, or thin-film lithium niobate – but largely the assembly techniques in photonics and propel them to the world of semiconductors. So that when we are building these PICs, they look like chip-scale semiconductors.

When we talk about semiconductorization, we’re basically talking about making photonics assembly look like semiconductor chips – which is using chip-scale, wafer-level manufacturing techniques – that are what people use in semiconductors. There’s some sort of a one-to-one correlation between semiconductor chips and photonic chips. They are both being built at wafer scale in large silicon fabs. 

That whole concept of scale – size, miniaturization, form factor, performance – largely dovetails with what Moore’s Law has been doing for decades in the world of semiconductors. And we’re just trying to get onto that trajectory. That’s the term semiconductorization that we’ve been using at POET.

\[17:48\] **Interviewer:** Okay, and you mentioned a little while ago about Foxconn as one of your customers; I think it is Foxconn Interconnect Technology to mention their full name. They have chosen, I think, your optical engine to use in their optical transceiver modules. If you are able,  – I suspect obviously some of it is sort of secret – but if you can share some of the sort of background to the way you’re working with them as a partner?

\[18:12\] **Suresh Venkatesan:** Yeah, I think there are technical requirements and volume requirements around 800G moving on to 1.6T and beyond. That’s clearly one piece of it. There’s also the geopolitical aspect of needing module makers not necessarily all concentrated inside of China – that’s another piece of it. Luxshare and Foxconn are Taiwanese companies, even if they have some operations in China. 

So, I think our partnerships with some of these companies are largely to provide a more expansive set of solutions to this rapidly growing AI space. Our engagement with Foxconn Interconnect is largely for them to use our engines  to create modules for 800G and 1.6T. We’re starting out with 800G DR8, which is one of the solutions that they’re excited about taking to market.

But like I said, for us and them, it’s relatively seamless. Once you make a commitment to using the POET optical engine, the transition from DR8 to FR4, to linear pluggable optics is relatively transparent. The same or largely the same module capabilities and design can work across all of these different form factors. So, while it starts out with the focus on a specific product – which is an 800G DR8 application – we do expect that it’s going to proliferate from there into multiple form factors and speeds as well.

\[20:05\] **Interviewer:** In terms of AI, which you’ve referenced a few times, and interconnect technology, particularly in the data center space, there is clearly a massive need at the moment with all these large language models and the number crunching going on. Do you think, in the longer term, there’s still going to be a massive requirement for AI? Or once AI applications get out there, will things calm down a bit? Or, because there will be so many of them and they all demand the sort of feeds and speeds we’ve been talking about, will there still be significant demand for the AI infrastructure?

\[20:38\] **Suresh Venkatesan:** Yeah, I mean, that’s a crystal ball question. But I think, as has happened recently, once the software associated with programming for training and inferencing is available, and now that you’ve got these large language models, the pendulum has kind of switched a little bit to: “Okay, is my hardware compatible and capable of doing what we need it to do?” And clearly, it’s not, right? 

So, there’s this huge resurgence in increasing the number of GPU cores. If you look at the latest NVIDIA processor, it’s like two to three times larger than the one before it. So yes, there’s going to be a need for more and more compute power, compute power at better power efficiency, in terms of how much power is consumed. I don’t think that that’s fundamentally going to change. 

But what we see happening is that the more data that you are piping through these GPUs or compute servers or AI servers, there are starting to be bottlenecks – bottlenecks in terms of memory access, bottlenecks in terms of CPU access, and so on. So, there’s this trend towards: “How do I reduce those bottlenecks?” Most of the approaches are to eliminate the latency in data transfer between chips, or between chips and memory, and so on. 

While there is this big growth associated with optics in AI, largely for node-to-node communications, there is clearly a trend towards getting closer-reach optical communications – between chips, chips and memory, disaggregated systems. We see that happening. The question is not *if* it’s going to happen, it’s *when* it’s going to happen. 

Most of these transitions, when they happen, they happen, and the spigot turns on. But still it happens …, you know, it’s always the next thing that’s going to happen. That’s typically how transitions in the industry happen. I mean, it happened with analog cell phones going to digital. Back in the days, in the 90s, it was all analog, analog, analog – boom! The spigot turned to digital one day, and everything was digital. 

We expect the same thing to happen. So a lot of what we’re doing is preparing for that transition to occur, where that significant increase in volume is going to be. There are a lot of companies in that space now, effectively working on chip-to-chip and solutions that are all kind of waiting for that ultimate transition to occur – when copper absolutely runs out of steam and there is a cost-effective solution for photonics to take over. 

We see that imminently. I mean, it’s not next year, but it’s probably not 10 years either. So there’s going to be a transition, and that transition is imminent. And when that transition happens this need for integration in photonics, the need for large-scale, small form-factor, low-cost photonic components is just going to be there, and we see that happening.

So I don’t see things slowing down actually. I think that large language models are going to get larger and larger. They’re going to put more and more demands on the processors, they’re going to put more and more demands on latency. Optics is a path to solve these latency issues. I think it’s being primed now by companies like POET and several others to meet the requirements when that spigot turns on.

\[24:22\] **Interviewer:** Okay. Just before we finish, just a couple of things also to ask. I think you’re also working alongside MultiLane, if I remember correctly. I don’t know. Can you again share a bit about the sort of work you’re doing with them at the moment? That would be good.

\[24:34\] **Suresh Venkatesan:** Yeah, they are a customer and a collaborator with us. They have got a presence in the high-speed optical test and measurements area. They are very well reputed. They’ve got some module manufacturing capabilities and are keen on entering into these really high-speed 800G and beyond module space. 

And as I said: By using our integrated engines – since we take care of a lot of the optical path design onto the chip itself – their ability to use our engines and create modules is simpler, lower CapEx, lower complexity. So, we’re partnering with them to create fully POET-based 800G transceiver modules, and then, of course, moving on to 1.6T. 

They are going to be potentially a manufacturing source for us for modules and as well a customer, because they are going to be also making and selling modules. It’s a really great relationship. We just started working with them over the past couple of quarters. We would expect the fruits of our labor to show up sometime next year.

\[25:55\] **Interviewer:** Okay. And then maybe just finally, you’ve alluded to quite a lot of what’s going on and maybe into the future. But just in terms of the roadmap, it sounds to a certain extend as if you’ve been waiting for everyone else to catch up with you, and now that’s beginning to happen. So I imagine you’ll try to keep ahead. Is there anything you can share just about technologies you’re looking to develop further or just again about growing the company in terms of your partner base etc.? Just anything you can share?

\[26:21\] **Suresh Venkatesan:** I guess the way I look at it is: We’ve got 100G solutions, and we’ve got some customers, and they are designing us in. And if and when  they ramp – which they would, I think, soon – we’re going to supply them. But that is not where our focus right now is.

Our focus right now is to capitalize on the large opportunities at 800G and ensure that customers know and understand that our platform is scalable to 3.2T. It’s really important. As a startup, it’s often difficult. You’re chasing near-term revenue. But you are a new company, you are a new technology, you have to show that the investment that a customer puts into you for differentiation is a long-term play and it’s not something that is a one-and-done or a one note.

You always have to also be kind of at that leading edge, and that becomes a balance, because of course if we put all our focus on 3.2T that revenue would show up much later. But it’s also an important flag to plant, because if we plant that flag then people are like: “Okay, let’s work with them now. We know there’s going to be a solution with them four years or five years from now.” 

So yes, we do have this focus on getting the 800G products to the market. But at the same time, we have an aggressive plan to showcase our technology up at the 3.2T level over the course of the next year.

\[27:57\] **Interviewer:** Okay, it’s been brilliant to chat and some really great insights and information about what’s going on at POET and thoughts. I guess the the photonics market will change. Suresh, really appreciate your time. Thank you very much!

\[28:09\] **Suresh Venkatesan:** Thank you.
